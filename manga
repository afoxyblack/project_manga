#!/bin/bash

clear

echo
echo "   -==============================- "
echo "  |                                |"
echo "  |  Качалка для манги и комиксов. |"
echo "  |                     20211022_1 |"
echo "   -==============================- "
echo

# =====> Настройки скрипта. Начало <====================================

# Определяем использование реальных имён картинок для сайтов, где возможен выбор. true - используются реальные имена картинок, любое другое значение - используются предустановленные имена - Page_xxx.ext. Однако, если в папке с комиксом присутствует файл "real_names" или "real_names.txt", используются оригинальные имена картинок независимо от значения переменной. Файл создаётся сам, если один раз выбрать использование реальных имён, но можно создать его вручную.
REAL_NAMES=false

# Определяем использование реальных имён картинок acomics.ru. true - используются реальные имена картинок, любое другое значение - используются предустановленные имена - Page_xxxxxx.ext. Однако, если в папке с комиксом присутствует файл "real_names" или "real_names.txt", используются оригинальные имена картинок независимо от значения переменной. Файл создаётся сам, если один раз выбрать использование реальных имён, но можно создать его вручную.
ACOMICS_PICS_NAME_REAL=false

# Определяем для unicomics.ru, com-x.life и readcomiconline.to раскладку картинок по томам или главам. true - картинки раскладываются по томам, любое другое значение - раскладываются по главам, как в манге. Однако, если в папке с комиксом присутствует файл "by_volumes" или "by_volumes.txt", картинки раскладываются по томам принудительно, независимо от значения переменной. Файл создаётся сам, если один раз выбрать раскладку по томам, но можно создать его вручную.
BY_VOLUMES=false

# Определяем сохранять ли в папках с главами текстовые файлы с адресами глав. true - сохранять, любое другое значение - не сохранять.
SAVE_CH_LINK=true

# Запрет использования реферальной ссылки при закачке картинок. true - закачка без параметра --referer, любое другое значение - в качестве рефералки используется адрес главы. Однако, если в папке с комиксом присутствует файл "no_referer" или "no_referer.txt", реферальная ссылка не используется независимо от значения переменной. Файл создаётся сам, если один раз выбрать запрет рефералки, но можно создать его вручную.
NO_REFERER=false

# Для Мангалиб выбираем сервер картинок. Допустимые значения переменной: "main", "secondary", "compress" и "fourth". Всё без кавычек.
LIB_SERVER=compress

# Для Мангалиб определяем нужно ли сортировать по переводчикам список глав, полученных со страницы описания. true - выполнять сортировку, любое другое значение - выводить ссылки по порядку.
SORT_BID=true

# Определяем нужно ли оставлять времянки со ссылками на картинки в папке с комиксом. true - оставлять времянки, любое другое значение - времянки удаляются. Однако, если в папке с комиксом присутствует файл "leave_tmp" или "leave_tmp.txt", времянки остаются, независимо от значения переменной.
LEAVE_TMP=false

# =====> Настройки скрипта. Конец <=====================================

# Если используется Linux выполняется проверка наличия нужных бинарников, иначе проверка игнорируется.
if [ $(uname -o) = "GNU/Linux" ] ; then

	if [ ! -x /usr/bin/curl ] ; then
		echo "Файл /usr/bin/curl не обнаружен или не является исполняемым!" ; echo "Нужен для всех сайтов." ; echo ; sleep 5 ; exit
	fi
	if [ ! -x /bin/sed ] ; then
		echo "Файл /bin/sed не обнаружен или не является исполняемым!" ; echo "Нужен для всех сайтов." ; echo ; sleep 5 ; exit
	fi
	if [ ! -x /usr/bin/tac ] ; then
		echo "Файл /usr/bin/tac не обнаружен или не является исполняемым!" ; echo "Нужен для всех сайтов." ; echo ; sleep 5 ; exit
	fi
	if [ ! -x /bin/cat ] ; then
		echo "Файл /bin/cat не обнаружен или не является исполняемым!" ; echo "Нужен для всех сайтов." ; echo ; sleep 5 ; exit
	fi
	if [ ! -x /usr/bin/awk ] ; then
		echo "Файл /usr/bin/awk не обнаружен или не является исполняемым!" ; echo "Нужен для сайтов readmanga.live, mintmanga.live, selfmanga.ru полных версий www.mangahere.cc и www.mangatown.com." ; echo ; sleep 5 ; exit
	fi
	if [ ! -x /bin/grep ] ; then
		echo "Файл /bin/grep не обнаружен или не является исполняемым!" ; echo "Нужен для сайтов jurnalu.ru и полной версии fanfox.net." ; echo ; sleep 5 ; exit
	fi
	if [ ! -x /usr/bin/seq ] ; then
		echo "Файл /usr/bin/seq не обнаружен или не является исполняемым!" ; echo "Нужен для сайта unicomics.ru." ; echo ; sleep 5 ; exit
	fi

fi

# Если скрипт запущен на Android в Termux, то выполняется проверка наличия нужных бинарников, иначе проверка игнорируется. Список предустановленных бинарников может измениться. Раньше нужны были эти пакеты, на данный момент sed и curl уже предустановлены, но на всякий случай оставим их проверку.
if [ $HOME = /data/data/com.termux/files/home ] ; then
	
	if [ ! -x /data/data/com.termux/files/usr/bin/sed ] ; then
		echo -e "Приложение \e[1;32msed\e[0m не установлено." ; echo "Для установки введите команду:" ; echo "  pkg install sed" ; echo ; sleep 5 ; exit
	fi
	if [ ! -x /data/data/com.termux/files/usr/bin/curl ] ; then
		echo -e "Приложение \e[1;32mcurl\e[0m не установлено." ; echo "Для установки введите команду:" ; echo "  pkg install curl" ; echo ; sleep 5 ; exit
	fi
	if [ ! -x /data/data/com.termux/files/usr/bin/file ] ; then
		echo -e "Приложение \e[1;32mfile\e[0m не установлено." ; echo "Для установки введите команду:" ; echo "  pkg install file" ; echo ; sleep 5 ; exit
	fi
	if [ ! -x /data/data/com.termux/files/usr/bin/zip ] ; then
		echo -e "Приложение \e[1;32mzip\e[0m не установлено." ; echo "Для установки введите команду:" ; echo "  pkg install zip" ; echo ; sleep 5 ; exit
	fi
fi

# User Agent. Кем будет "прикидываться" качалка.
if [ $(uname -o) = "MS/Windows" ] ; then
	# Firefox 84.0, Windows 10 x86_64
	UA="Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0"
elif [ $(uname -o) = "Android" ] ; then
	# Firefox 84.0, Android 10
	UA="Mozilla/5.0 (Android 10; Mobile; rv:92.0) Gecko/84.0 Firefox/92.0"
else
	# Firefox 84.0, Fedora 33 x86_64
	UA="Mozilla/5.0 (X11; Fedora; Linux x86_64; rv:92.0) Gecko/20100101 Firefox/92.0"
fi

# =====> Объявление функций. Начало <===================================

# Сообщение о смене адреса сайта.
Change_site_message () {
	echo -e "\e[1;33m  Сайт сменил адрес. Подменяем его на актуальный $SITE.\e[0m" ; echo
}

# Проверка сайта на актуальность для сайтов-мигрантов и замена при необходимости.
Adres_check_replace () {
	if [ $SITE != $(echo $ADRES | sed -e 's|.*://||' -e 's|/.*||') ] ; then
		echo -e "\e[1;33m  Подменяем адрес сайта в адресе комикса.\e[0m"
		ADRES=$(echo "$(echo $ADRES | sed 's|://.*||')://$SITE/$(echo $ADRES | cut -d "/" -f "4-")")
		echo -e "\e[1;33m  Новый адрес комикса — $ADRES\e[0m" ; echo
		sleep 2
	fi
}

# Только для Мангалиб. Сортировка списка ссылок, полученных со страницы описания, по ID переводчиков.
Sort_bid () {
	
	# Проверяем значение переменной. Если true - продолжаем, иначе - ничего не меняем. Про sort подробно написано на https://aidalinux.ru/w/Sort .
	if [ $SORT_BID = true ] ; then
		sort -t "=" -snk2
	else
		tac | tac
	fi
}

# Проверка файла ch_adreses.txt на непустоту. Если размер файла равен нулю, ругаемся и выходим.
Check_ch_adreses () {
	
	if [ ! -s ch_adreses.txt ] ; then
		echo
		echo -e "\e[1;31m  Что-то пошло не так! Не получается сформировать список глав.\e[0m"
		echo -e "\e[1;31m     Возможно что-то поменялось на сайте или сайт переехал.\e[0m"
		echo -e "\e[1;31m   Попробуйте скачать позже или проверьте обновление качалки.\e[0m"
		echo
		sleep 5
		exit
	fi
}

# Выбор количества скачиваемых глав.
Download_choice () {
	
	# Открывает файл ch_adreses.txt в консоли для просмотра количества глав (строк в файле)
	echo
	echo "Содержимое файла ch_adreses.txt с указанием номеров строк"
	echo
	sleep 1
	cat -n ch_adreses.txt
	
	# Определяем количество скачиваемых глав
	echo
	echo "Введите номер первой скачиваемой главы (строки файла ch_adreses.txt)"
	echo "или просто нажмите [Enter] для закачки с первой главы"
	echo "Если нужно, используйте прокрутку"
	echo
	read F_CHAP
	echo
	echo "Введите номер последней скачиваемой главы (строки файла ch_adreses.txt)"
	echo "или просто нажмите [Enter] для закачки до последней главы"
	echo
	read E_CHAP
	echo
	
	#Вводим переменную MAX_CHAP, содержащую количество строк файла ch_adreses.txt для проверки правильности ввода последней скачиваемой главы
	MAX_CHAP=$(sed -n '$=' ch_adreses.txt)
	
	# Если переменной F_CHAP значение не присвоено, используется дефолтное значение 1.
	F_CHAP=${F_CHAP:-1}
	
	# Если переменной E_CHAP значение не присвоено, используется значени MAX_CHAP.
	E_CHAP=${E_CHAP:-$MAX_CHAP}
	
	# Проверяем значение номера последней главы и, если оно больше количества существующих, то уменьшаем до допустимого
	if [ $E_CHAP -gt $MAX_CHAP ] ; then
		
		E_CHAP=$MAX_CHAP
	fi
	
	touch "Главы с $F_CHAP по $E_CHAP скачиваются"
	
	# Присваиваем переменной i номер первой скачиваемой главы, если глава не задана, то i=1
	i=$F_CHAP
}

# Определяем  какую разбивку картинок использовать, по томам или главам и отправляем в переменную путь скачивающегося тома. Переменная требуется для дальнейшей проверки полноты закачки.
Separation_by () {
	
	# Проверяем значение переменной.
	if [ $BY_VOLUMES = true ] ; then
	
		# Используем разбивку по томам. В папке с комиксом оставляем файл-отметку для последующих закачек в эту папку.
		touch "by_volumes.txt"
		PICS_PATH=Pics\/vol_$i
	else
		# Если в начале скрипта выбрана разбивка по главам (false), проверяем наличие в папке файла "by_volumes" или "by_volumes.txt" (для отмены предустановки), и, если он отсутствует, используем разбивку по главам.
		if [ -f by_volumes -o -f by_volumes.txt ] ; then
			PICS_PATH=Pics\/vol_$i
		else
			PICS_PATH=Pics\/vol_\/"$(printf "%03d" $i)"
		fi
	fi
}

# Сохраняем в папке с главой текстовый файл со ссылкой на неё.
Save_chapter_link () {
	
	# Проверяем значение переменной. Если true - продолжаем, иначе - ничего не делаем.
	if [ $SAVE_CH_LINK = true ] ; then
	
		if [ ! -f ""$PICS_PATH"/"$SITE".txt" ] || [ ! -s ""$PICS_PATH"/"$SITE".txt" ] ; then
			echo "This chapter was downloaded $(date +%d.%m.%Y" at "%H:%M) from $(sed -n "$i p" ch_adreses.txt)" > "$PICS_PATH"/"$SITE".txt
		fi
	fi
}

# Определям, какие имена картинок использовать - оригинальные или предустановленные.
Determ_name () {
	
	# Проверяем значение переменной.
	if [ $REAL_NAMES = true ] ; then
	
		# Используем оригинальное имя. В папке с комиксом оставляем файл-отметку для последующих закачек в эту папку.
		touch "real_names.txt"
		PIC_NAME=$PIC_NAME
	else
		# Если в начале скрипта выбрано использование имён вида Page_xxx.ext (REAL_NAMES=false), проверяем наличие в папке файла "real_names" или "real_names.txt" (для отмены предустановки), и, если он отсутствует, используем имя файла Page_xxx.ext.
		if [ -f real_names -o -f real_names.txt ] ; then
			PIC_NAME=$PIC_NAME
		else
			PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $PIC_NAME | sed 's/.*\.//'))
		fi
	fi
}

# Объявляем функцию проверки расширения и его замены, если потребуется. Используется в следующей функции.
Check_rename () {
	
	# Получаем внешнее расширение файла из строки списка. Полученное расширение приводится к нижнему регистру. Это позволит избежать переименования при несовпадении регистра при сравнении.
	EXT_EXT=$(echo "$PIC_NAME" | sed 's/.*\.//' | tr '[:upper:]' '[:lower:]')
	
	# Сравниваем расширение файла с его истинным расширением. Если расширения отличаются - переименовываем, если нет - пропускаем.
	if [ "$INT_EXT" != "$EXT_EXT" -a "$INT_EXT2" != "$EXT_EXT" ] ; then
		mv "$PICS_PATH"\/"$PIC_NAME" "$(echo "$PICS_PATH"\/"$PIC_NAME" | sed 's/\.[^\.]*$//')"."$INT_EXT"
		echo -e "\e[1;33m  Расширение файла неверное. Исправлено на \"$INT_EXT\".\e[0m"
		echo
	fi
}

# Закачка картинок и проверка. Часть цикла.
Downloading_pics () {
	
	# Вывод количества картинок в главе и прямой ссылки на картинку.
	echo -e "    Скачивается страница \e[1;32m$j\e[0m из \e[1;32m$(sed -n '$=' pics_$i.txt)\e[0m главы \e[1;32m$i\e[0m."
	echo
	echo -e "    Ссылка \"\e[1;34m$LINK_PIC\e[0m\" будет сохранена в файл \"$PWD/"$PICS_PATH"/\e[1;34m"$PIC_NAME"\e[0m\"." ; echo
	
	# Скачиваем картинку по ссылке с помощью curl. Использование реферальной ссылки определяется переменной в начале скрипта или файлом "no_referer" ("no_referer.txt") в папке с комиксом.
	# Проверяем значение переменной.
	if [ $NO_REFERER = true ] ; then
	
		# Если выбран запрет на использование реферальной ссылки.
		touch "no_referer.txt"
		curl -k -L -A "$UA" -f -C - "$LINK_PIC" -o "$PICS_PATH"\/"$PIC_NAME"
		
	else
		# Если в начале скрипта выбрано использовать рефералку, проверяем наличие в папке файла "no_referer" или  "no_referer.txt" (для отмены предустановки), и, если он отсутствует, в качестве рефералки используем ссылку на главу.
		if [ -f no_referer -o -f no_referer.txt ] ; then
			
			curl -k -L -A "$UA" -f -C - "$LINK_PIC" -o "$PICS_PATH"\/"$PIC_NAME"
		else
			curl -k -L --referer "$(sed -n "$i p" ch_adreses.txt)" -A "$UA" -f -C - "$LINK_PIC" -o "$PICS_PATH"\/"$PIC_NAME"
		fi
	fi
	
	# Проверяем код возврата и выводим соответствующее сообщение. Если нужно вывести код возврата в терминал для отладки, сначала сохранить его в переменную, затем вывести с помощью echo после чего можно проверять. Иначе, если просто использовать echo, в сравнение попадает код возврата echo.
	if [ "$?" -eq 0 ] ; then
		echo ; echo -e "\e[1;32m\tСтраница $j из $(sed -n '$=' pics_$i.txt) главы $i закачана.\e[0m" ; echo
	else
		if [ -f ""$PICS_PATH"/$PIC_NAME" ] || [ -s ""$PICS_PATH"/$PIC_NAME" ] ; then
			echo ; echo -e "\e[1;33m\tСтраница $j из $(sed -n '$=' pics_$i.txt) главы $i была закачана ранее.\e[0m" ; echo
		else
			echo ; echo -e "\e[1;31m\tСтраницу $j из $(sed -n '$=' pics_$i.txt) главы $i скачать не удалось.\e[0m" ; echo
			echo "    $(date +%c) - Страницу $j главы $i по ссылке \"$LINK_PIC\" скачать не удалось. Попробуйте перекачать её." >> "Ошибки при закачке.txt"
		fi
	fi
	
	# Выполним проверку расширения файла.
	# Определим внутреннее расширение файла.
	INT_EXT=$(file -b "$PICS_PATH"\/"$PIC_NAME" | cut -d ' ' -f '1') 
	
	case "$INT_EXT" in
	
		JPEG)
			INT_EXT=jpg
			INT_EXT2=jpeg
		;;

		PNG)
			INT_EXT=png
		;;

		GIF)
			INT_EXT=gif
		;;

		RIFF)
			INT_EXT=webp
		;;
	
	esac
	
	Check_rename
	
	# Отделим законченную закачку картинки
	echo "  ========================================================" ; echo
}

# Проверка полноты закачки. Сверяется количество строк в файле со ссылками на картинки и количество файлов в папке назначения. Не срабатывает на пустых файлах ,-(
Down_check () {
	
	# Для начала проверим, выбрано ли в начале скрипта сохранять в папку с главой файл со ссылкой
	if [ $SAVE_CH_LINK = true ] ; then
		
		# Если выбрано сохранять файл со ссылкой, к количеству строк в файле со ссылками на картинки прибавляется 1
		if [ ! -s pics_$i.txt ] || [ ! -d "$PICS_PATH" ] || [ $(ls -1 "$PICS_PATH" | sed -n '$=') -lt $(( $(sed -n '$=' pics_$i.txt)+1 )) ] ; then
			echo -e "\e[1;31mГлава $i скачалась не полностью.\e[0m" ; echo ; sleep 2
			echo -e "\n    $(date +%c) - Глава $i по ссылке \"$(sed -n "$i p" ch_adreses.txt)\" скачалась не полностью. Попробуйте перекачать её.\n\n" >> "Ошибки при закачке.txt"
		elif [ $(ls -1 "$PICS_PATH" | sed -n '$=') -gt $(( $(sed -n '$=' pics_$i.txt)+1 )) ] ; then
			echo -e "\e[1;31mХрень какая-то! (О_О) В папке \"$PWD/Pics/$i\" файлов больше, чем должно быть... Требуется вмешательство НЕискуственного интеллекта!\e[0m" ; echo ; sleep 2
			echo -e "\n    $(date +%c) - В папке \"$PWD/Pics/$i\" файлов больше, чем должно быть в главе $i по ссылке \"$(sed -n "$i p" ch_adreses.txt)\". Проверьте!\n\n" >> "Ошибки при закачке.txt"
		else echo -e "\e[1;32mГлава $i из $(sed -n '$=' ch_adreses.txt) закачана полностью.\e[0m" ; echo ; sleep 2
		fi
	
	else
		
		# Если выбрано не сохранять файл со ссылкой, данные сверяются как есть
		if [ ! -s pics_$i.txt ] || [ ! -d "$PICS_PATH" ] || [ $(ls -1 "$PICS_PATH" | sed -n '$=') -lt $(sed -n '$=' pics_$i.txt) ] ; then
			echo -e "\e[1;31mГлава $i скачалась не полностью.\e[0m" ; echo ; sleep 2
			echo -e "\n    $(date +%c) - Глава $i по ссылке \"$(sed -n "$i p" ch_adreses.txt)\" скачалась не полностью. Попробуйте перекачать её.\n\n" >> "Ошибки при закачке.txt"
		elif [ $(ls -1 "$PICS_PATH" | sed -n '$=') -gt $(sed -n '$=' pics_$i.txt) ] ; then
			echo -e "\e[1;31mХрень какая-то! (О_О) В папке \"$PWD/Pics/$i\" файлов больше, чем должно быть... Требуется вмешательство НЕискуственного интеллекта!\e[0m" ; echo ; sleep 2
			echo -e "\n    $(date +%c) - В папке \"$PWD/Pics/$i\" файлов больше, чем должно быть в главе $i по ссылке \"$(sed -n "$i p" ch_adreses.txt)\". Проверьте!\n\n" >> "Ошибки при закачке.txt"
		else echo -e "\e[1;32mГлава $i из $(sed -n '$=' ch_adreses.txt) закачана полностью.\e[0m" ; echo ; sleep 2
		fi
	
	fi
	
	# Удаляем времянку со списком ссылок на картинки.
	# Проверяем значение переменной.
	if [ $LEAVE_TMP != true ] ; then
		# Если в начале скрипта выбрано удалять времянку, проверяем наличие в папке файла "leave_tmp" или "leave_tmp.txt" (для отмены предустановки), и, если он отсутствует, удаляем времянку.
		if ! [ -f leave_tmp -o -f leave_tmp.txt ] ; then
			# Удаляем времянку.
			rm pics_$i.txt
		fi
	else
		# Если в начале скрипта выбрано оставлять времянку, оставляем в папке с комиксом файл-отметку для последующих закачек в эту папку.
		touch "leave_tmp.txt"
	fi
}

# Файл завершения закачки.
Echo_finish () {
	
	rm "Главы с $F_CHAP по $E_CHAP скачиваются"
	touch "Главы с $F_CHAP по $E_CHAP закачаны"
}

# Упаковка закачанного в CBZ.
Pack_to_CBZ () {
	
	# Перед упаковкой проверим наличие файла ошибок "Ошибки при закачке.txt", и, если он есть, выведем его содержимое в консоль
	if [ -s "Ошибки при закачке.txt" ] ; then
		
		# Отделим текушую сессию закачки в файле
		echo -e "========================================================\n" >> "Ошибки при закачке.txt"
		
		# Вывод содержимого файла ошибок в консоль
		echo
		echo "========================================================"
		echo
		cat "Ошибки при закачке.txt"
		echo
		echo -e "    \e[1;31mЕсли скачать с этого сайта не удаётся, попробуйте скачать позже или поищите в другом месте.\e[0m"
		echo
		echo "========================================================"
		echo
		sleep 5
	fi
	
	# Вывод сообщения об упаковке
	echo
	echo "========================================================"
	echo
	echo -e "\e[1;34mУпаковка томов в CBZ. Если не нужно - [Ctrl]+[C] или [х]\e[0m"
	
	# Вывод содержимого папки Pics (для просмотра номеров томов). Если нужен вывод томов в строку, убрать единицу ( ls ./Pics -v ).
	echo
	echo "Список томов в папке \"$PWD/Pics\""
	echo
	ls ./Pics -v1
	
	# Определяем количество пакуемых томов
	
	echo
	echo -e "\e[1;34mВведите номер первого пакуемого тома, для выборочной упаковки\e[0m"
	echo -e "\e[1;34mсо сменой имён архивов, если нужно. Введите только номер!\e[0m"
	echo
	echo -e "\e[1;34m  Или нажмите [Enter] для упаковки всего,\e[0m"
	echo -e "\e[1;34mиспользуя для названия архивов имена папок.\e[0m"
	echo
	read F_VOL
	echo

	# Проверяем введено что-нибудь или нет
	if [ $F_VOL ] ; then
		
		# Если введено какое-либо число, используем упаковку с перебором нумерации
		echo "Введите номер последнего пакуемого тома"
		echo
		read E_VOL
		echo
		echo "Введите название архивов и нажмите [Enter]."
		echo "Если ничего не вводить и нажать [Enter] используется \"vol\""
		echo
		read VOL_NAME
		
		# Если переменной VOL_NAME значение не присвоено, используем дефолтное значение vol
		VOL_NAME=${VOL_NAME:-vol}
		echo
		
		# Присваиваем переменной i номер первого пакуемого тома
		i=$F_VOL
		
		# Проверяем, что переменная i меньше номера последнего пакуемого тома
		while [ $i -le $E_VOL ] ; do
		
			# Упаковываем том
			# Переходим в каталог для упаковки.
			cd Pics/vol_$i
			
			# Проверяем код возврата и, если он равен нулю (успешно перешли в каталог), упаковываем содержимое. В противном случае, ругаемся и переходим к другому каталогу.
			if [ "$?" -eq 0 ]
			then
				zip -r ../../"$VOL_NAME"_$i.cbz .
				cd ../..
			else
				echo -e "\e[1;31m    Не удалось сменить каталог! Смотри ошибку строкой выше!\e[0m"
			fi
			
			# Увеличиваем i на единицу
			i=$(($i+1))
		done
	
	# Если ничего не введено, упаковываем всё используя для архивов имена папок
	else
		
		for v in $(ls Pics) ; do
			
			# Переходим в каталог для упаковки.
			cd Pics/$v
			
			# Проверяем код возврата и, если он равен нулю (успешно перешли в каталог), упаковываем содержимое. В противном случае, ругаемся и переходим к другому каталогу.
			if [ "$?" -eq 0 ]
			then
				zip -r ../../$v.cbz .
				cd ../..
			else
				echo -e "\e[1;31m    Не удалось сменить каталог! Смотри ошибку строкой выше!\e[0m"
			fi
		done
		
	fi
}

# =====> Объявление функций. Конец <====================================


# Использование диалога Zenity для определения папки назначения, если скрипт работает в Винде.
if [ $(uname -o) = "MS/Windows" ] ; then
	cd "$(zenity --title="Выберите папку для сохранения манги/комикса" --file-selection --directory)"
fi

# Если файл ch_adreses.txt с абсолютными адресами глав отсутствует или пуст, скрипт
# ищет файл adres.txt с адресом манги/комикса и если его не находит запрашивает
# адрес страницы описания комикса, закачивает html и формирует из него файл с адресами
if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then

	# Проверяем отсутствие adres.txt
	if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
		
		# Вывод запроса адреса манги. В Windows используется диалога Zenity, в остальных ОСях обходимся без него.
		if [ $(uname -o) = "MS/Windows" ] ; then
			# Win-style
			ADRES=$(zenity --entry --title="Вставьте адрес страницы описания манги/комикса, скопированный из адресной строки браузера и нажмите ОК" --text="" --entry-text="" --width=800)
		else
			#Lin-style
			echo "Введите адрес страницы описания комикса"
			echo
			read ADRES
			echo
		fi
		
	else ADRES=$(cat adres.txt)

	fi

	# Проверяем наличие http или https в начале ссылки.
	if [ $(echo $ADRES | sed "s|\/.*||") != "http:" ] && [ $(echo $ADRES | sed "s|\/.*||") != "https:" ] ; then
		echo -e "\e[1;31m  Ссылка должна начинаться с http или https.\e[0m"
		echo -e "\e[1;31m  Попробуйте ещё раз.\e[0m"
		echo
		sleep 5
		exit
	fi
	
	# Определяем к какому сайту относится ссылка.
	SITE=$(echo $ADRES | sed "s/.*:\/\///" | sed "s/\/.*//")
	

else
	
	# При наличии файла ch_adreses.txt используемые парсеры определяем по первой строке.
	SITE=$(sed -n 1p ch_adreses.txt | sed -e "s/.*:\/\///" -e "s/\/.*//")
	
	# Чтобы в нижеидущем сообщении не получился пустой адрес, выводим в переменную содержимое adres.txt
	ADRES=$(cat adres.txt)
fi

	echo "Скачивается комикс, расположенный по адресу \"$ADRES\""
	echo

# В зависимости от сайта используем соответствующие парсеры.
case $SITE in

# =====> Парсеры. Начало <==============================================

	# Если сайт определён как acomics.ru. Парсер сильно отличается от остальных, т.к. на сайте нет разбивки по томам и главам.
	acomics.ru)
		
		# Определяем название комикса
		COMIC_NAME=$(echo "$ADRES" | sed -e 's/.*acomics.ru\///' -e 's/\/.*//')
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "https://acomics.ru/$COMIC_NAME/about" > adres.txt
		fi
		
		# Выясняем количество выпусков на данный момент. Для этого скачаем первую страницу комикса
		MAX_PIC=$(curl -# -k -L -A "UA" -d ageRestrict=18 https://acomics.ru/$COMIC_NAME/1 | sed -n '/issueNumber/p' | sed -e 's/<\/.*//' -e 's/.*\///')
		
		# Определяем количество скачиваемых страниц
		echo
		echo -e "  Доступно для скачивания \e[1;32m$MAX_PIC\e[0m страниц комикса."
		echo
		echo "Введите номер первой скачиваемой страницы и нажмите [Enter]"
		echo "или просто нажмите [Enter] для скачивания с первой страницы"
		echo
		read FIRST_PIC
		echo
		echo "Введите номер последней скачиваемой страницы и нажмите [Enter]"
		echo "или просто нажмите [Enter] для скачивания до последней вышедшей страницы"
		echo
		read END_PIC
		echo
		
		# Если переменной FIRST_PIC значение не присвоено, используется дефолтное значение 1.
		FIRST_PIC=${FIRST_PIC:-1}
		
		# Если переменной END_PIC значение не присвоено, используется значение MAX_PIC.
		END_PIC=${END_PIC:-$MAX_PIC}
		
		# Проверяем значение номера последней страницы и, если оно больше количества выпусков, то уменьшаем до допустимого
		if [ $END_PIC -gt $MAX_PIC ] ; then
		
			END_PIC=$MAX_PIC
		fi
		
		touch "Страницы с $FIRST_PIC по $END_PIC скачиваются"
		
		# Присваиваем переменной i номер первой скачиваемой страницы
		i=$FIRST_PIC
		
		# Проверяем, что переменная i меньше номера последней скачиваемой страницы
		while [ $i -le $END_PIC ] ; do
		
			# Получаем прямую ссылку на закачку картинки. ageRestrict - проверка возраста читателя.
			LINK_PIC=$(curl -# -k -L -A "$UA" -d ageRestrict=18 https://$SITE/$COMIC_NAME/$i | sed -n '/mainImage/{n;p;}' | sed -e "s|.*src=\"|https://$SITE|" -e 's/".*//')
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p Pics\/vol_
			
			# Создаём в папке с комиксом текстовый файл с его адресом, если его там ещё нет.
			# Проверяем значение переменной. Если true - продолжаем, иначе - ничего не делаем.
			if [ $SAVE_CH_LINK = true ] ; then
			
				if [ ! -f "Pics/vol_/acomics.ru.txt" ] || [ ! -s "Pics/vol_/acomics.ru.txt" ] ; then
					echo "This comic was downloaded from \"https://$SITE/$COMIC_NAME/about\"." > "Pics/vol_/acomics.ru.txt"
				fi
			fi
			
			# Определяем, какое имя использовать для картинки - оригинальное или предустановленное.
			if [ $ACOMICS_PICS_NAME_REAL = true ] ; then
			
				# Используем оригинальное имя с сайта. В папке с комиксом оставляем файл-отметку для последующих закачек в эту папку.
				touch "real_names.txt"
				PIC_NAME=$(echo $LINK_PIC | sed 's/.*\///')
			else
				# Если в начале скрипта выбрано предустановленное имя, проверяем наличие в папке файла "real_names" или "real_names.txt" (для отмены предустановки), и, если он отсутствует, используем предустановленное имя файла. Расширение определяется с помощью ссылки на файл.
				if [ -f real_names -o -f real_names.txt ] ; then
					PIC_NAME=$(echo $LINK_PIC | sed 's/.*\///')
				else
					PIC_NAME="Page_$(printf "%06d" $i).$(echo $LINK_PIC | sed 's/.*\.//')"
				fi
			fi
			
			# Вывод прямой ссылки на картинку.
			echo ; echo -e "    Ссылка \"\e[1;34m$LINK_PIC\e[0m\" будет сохранена в файл \"$PWD/Pics/vol_/\e[1;34m"$PIC_NAME"\e[0m\"." ; echo
			
			# Скачиваем картинку.
			curl -k -L -A "$UA" -f -C - $LINK_PIC -o Pics\/vol_\/"$PIC_NAME"
			
			# Проверяем код возврата и выводим соответствующее сообщение. Если нужно вывести код возврата в терминал для отладки, сначала сохранить его в переменную, затем вывести с помощью echo после чего можно проверять. Иначе, если просто использовать echo, в сравнение попадает код возврата echo.
			if [ "$?" -eq 0 ] ; then
				echo ; echo -e "\e[1;32m\tСтраница $i из $MAX_PIC закачана.\e[0m" ; echo
			else
				if [ -f "Pics/vol_/"$PIC_NAME"" ] || [ -s "Pics/vol_/"$PIC_NAME"" ] ; then
					echo ; echo -e "\e[1;33m\tСтраница $i из $MAX_PIC была закачана ранее.\e[0m" ; echo
				else
					echo ; echo -e "\e[1;31m\tСтраницу $i по ссылке \"$LINK_PIC\" скачать не удалось.\e[0m" ; echo
					echo "    $(date +%c) - Страницу $i по ссылке \"$LINK_PIC\" скачать не удалось. Попробуйте перекачать её." >> "Ошибки при закачке.txt"
				fi
			fi
			
			# Отделим законченную закачку картинки
			echo "  ========================================================" ; echo
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		rm "Страницы с $FIRST_PIC по $END_PIC скачиваются"
		touch "Страницы с $FIRST_PIC по $END_PIC закачаны"
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как readmanga.live, mintmanga.live или selfmanga.live
	# Здесь перечислены все возможные адреса для этого парсера. Обратные слэши в конце строк экранируют символы окончания строк, чтобы все эти строки воспринимались как одна.
	readmanga.io | readmanga.live | readmanga.me | readmanga.ru |\
	mintmanga.live | mintmanga.com | adultmanga.ru |\
	selfmanga.live | selfmanga.me | selfmanga.ru)
	
		# Получаем имя манги
		COMIC_NAME=$(echo $ADRES | sed -e "s/.*$SITE\///" -e "s/\/.*//")
		
		# Получаем ID команды переводчиков. Откусывам по кусочкам ненужное, которого может и не быть.
		TRAN=$(echo $ADRES | sed -e "s/.*$COMIC_NAME//" -e 's/.*mtr=1//' -e 's/#.*//' -e 's/.*tran=//')
		
		# Если адрес сайта определён как устаревший выполняем подмену на актуальный.
		case $SITE in
			
			# Здесь указаны актуальные адреса для этого парсера. Совпадение означает "всё ОК, продолжаем дальше".
			readmanga.io | mintmanga.live | selfmanga.live)
			;;
			
			# Здесь перечислены все старые адреса Ридманги.
			readmanga.live | readmanga.me | readmanga.ru)
				
				# Здесь указан актуальный адрес Ридманги.
				SITE=readmanga.io
				Change_site_message
			;;
			
			# Здесь перечислены все старые адреса Минтманги.
			mintmanga.com | adultmanga.ru)
				
				# Здесь указан актуальный адрес Минтманги.
				SITE=mintmanga.live
				Change_site_message
			;;
			
			# Здесь перечислены все старые адреса Селфманги.
			selfmanga.me | selfmanga.ru)
				
				# Здесь указан актуальный адрес Селфманги.
				SITE=selfmanga.live
				Change_site_message
			;;
			
			# Если забыли добавить устаревший адрес в кейс.
			*)
				echo -e "\e[1;31m  Вы забыли добавить сайт \"$SITE\" в список устаревших для данного парсера!\e[0m" ; echo
				sleep 5 ; exit
		    ;;
		esac
		
		# Проверяем адрес и переопределяем при необходимости.
		Adres_check_replace
		
		# Сохраняем файл с адресом. При необходимости заменяем на актуальный.
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] || [ $SITE != $(cat adres.txt | sed -e 's|.*://||' -e 's|/.*||') ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "https://$SITE/$COMIC_NAME" | sed -n "/.*<a href.*\/vol.*/p" | sed -e "/>.*</d" -e '/;page=/d' | sed -e "s/.*<a href=\"/https:\/\/$SITE/g" -e "s/\".*/\?mtr=1\&tran="$TRAN"/g" | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав.
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
			
			# Определяем номер тома текущей главы
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e 's/.*vol//' -e 's/\/.*//')
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed  -n '/rm_h.init/p' | sed -e "s/^.*\[\['//" -e "s/\]\].*//" -e 's/\],\[./\n/g' | awk 'BEGIN { FS=".,." } { print $1 $3 }' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки. Можно обойтись без этой строки, пригодится для обобщения методов
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Получаем полное имя файла из ссылки на файл
				PIC_NAME=$(echo "$LINK_PIC" | sed -e 's/\?t=.*//' -e 's/.*\///')
				
				# Определяем, какое имя для картинки использовать. Зависит от переменной в начале скрипта
				Determ_name
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как manga-chan.me
	# Здесь перечислены все возможные адреса для этого парсера.
	manga-chan.me | mangachan.me | mangachan.ru)
		
		# Для старых адресов сайта выполняем замену на актуальный.
		# Если адрес сайта не равен актуальному...
		if [ $SITE != manga-chan.me ] ; then
			
			# ... заменяем его на актуальный.
			SITE=manga-chan.me
			Change_site_message
		fi
		
		# Проверяем адрес и переопределяем при необходимости.
		Adres_check_replace
		
		# Сохраняем файл с адресом. При необходимости заменяем на актуальный.
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] || [ $SITE != $(cat adres.txt | sed -e 's|.*://||' -e 's|/.*||') ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n "/class='manga/p" | sed -e "s|.*href='|https://$SITE|g" -e "s/'.*//g" | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав.
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Определяем номер тома текущей главы
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e 's/.*_v//' -e 's/_ch.*//')
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/"fullimg"/p' | sed 's/",/\n/g' | sed -e 's/.*"fullimg".*"//' -e 's/^"//g' -e 's/".*//g' -e 's/http:/https:/g' | sed -n '/https:/p' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки.
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Получаем полное имя файла из ссылки на файл
				PIC_NAME=$(echo $LINK_PIC | sed 's/.*\///')
				
				# Определяем, какое имя для картинки использовать. Зависит от переменной в начале скрипта
				Determ_name
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка полноты закачки.
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как fanfox.net или m.fanfox.net
	fanfox.net | m.fanfox.net)
		
		# Подменяем полный адрес на мобильный. Закачка с полной версии уже давно не работает.
		echo -e "\e[1;33mЕсли введён полный адрес, подменяем его на мобильный.\e[0m" ; echo
		ADRES=$(echo $ADRES | sed 's|\/fanfox.net\/|\/m.fanfox.net\/|g')
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Переопределяем переменную $SITE, чтобы избежать дублирования файла с адресом главы в папке с картинками, иначе сначала формируется файл со ссылкой на полную версию сайта и таким же именем, а при повторной закачке в эту же папку (сбой, недокачалось) формируется ещё и файл со ссылкой на мобильную версию сайта.
		SITE=$(echo $ADRES | sed "s/.*:\/\///" | sed "s/\/.*//")
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/<a href=".*html">/p' | sed -e 's/.*="/http:/g' -e 's/\/manga\//\/roll_manga\//g' -e 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Определяем номер тома текущей главы. 0* в выражении, для удаления лидирующего нуля, мешающего упаковке.
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e 's/.*\/v0*//' -e 's/\/.*//' -e 's/https*://')

			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/data-original/p' | sed -e 's/.*data-original="/https:/g' -e 's/amp;//g' -e 's/".*//g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки. Можно обойтись без этой строки, пригодится для обобщения методов
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Получаем полное имя файла из ссылки на файл
				PIC_NAME=$(echo "$LINK_PIC" | sed -e 's/\?token.*//' -e 's/.*\///')
				
				# Определяем, какое имя для картинки использовать. Зависит от переменной в начале скрипта
				Determ_name
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как www.mangahere.cc или m.mangahere.cc
	www.mangahere.cc | m.mangahere.cc)
		
		# Подменяем полный адрес на мобильный. Закачка с полной версии уже давно не работает.
		echo -e "\e[1;33mЕсли введён полный адрес, подменяем его на мобильный.\e[0m" ; echo
		ADRES=$(echo $ADRES | sed 's|\/www.mangahere.cc\/|\/m.mangahere.cc\/|g')
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Переопределяем переменную $SITE, чтобы избежать дублирования файла с адресом главы в папке с картинками, иначе сначала формируется файл со ссылкой на полную версию сайта и таким же именем, а при повторной закачке в эту же папку (сбой, недокачалось) формируется ещё и файл со ссылкой на мобильную версию сайта. 
		SITE=$(echo $ADRES | sed "s/.*:\/\///" | sed "s/\/.*//")
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/<li><a.*m.mangahere/p' | sed -e 's/.*="/http:/g' -e 's/\/manga\//\/roll_manga\//g' -e 's/\/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Определяем номер тома текущей главы. 0* в выражении, для удаления лидирующего нуля, мешающего упаковке.
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e 's/.*\/v0*//' -e 's/\/.*//' -e 's/https*://')
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/data-original/p' | sed -e 's/.*data-original="/http:/g' -e 's/".*//g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Получаем полное имя файла из ссылки на файл
				PIC_NAME=$(echo "$LINK_PIC" | sed -e 's/\?token.*//' -e 's/.*\///')
				
				# Определяем, какое имя для картинки использовать. Зависит от переменной в начале скрипта
				Determ_name
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как мобильный www.mangatown.com или m.mangatown.com
	www.mangatown.com | m.mangatown.com)
		
		# Подменяем полный адрес на мобильный. Закачка с полной версии уже давно не работает.
		echo -e "\e[1;33mЕсли введён полный адрес, подменяем его на мобильный.\e[0m" ; echo
		ADRES=$(echo $ADRES | sed 's|\/www.mangatown.com\/|\/m.mangatown.com\/|g')
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Переопределяем переменную $SITE, чтобы избежать дублирования файла с адресом главы в папке с картинками, иначе сначала формируется файл со ссылкой на полную версию сайта и таким же именем, а при повторной закачке в эту же папку (сбой, недокачалось) формируется ещё и файл со ссылкой на мобильную версию сайта. 
		SITE=$(echo $ADRES | sed "s/.*:\/\///" | sed "s/\/.*//")
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/a href=\".*\/manga\//p' | sed -e 's/.*href="//g' -e 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Определяем номер тома текущей главы. 0* в выражении, для удаления лидирующего нуля, мешающего упаковке.
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e 's/.*\/v0*//' -e 's/\/.*//' -e 's/https*://')
			
			# Формируем файл с непрямыми ссылками на картинки текущей главы
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/option value.*manga/p' | sed -e 's/.*value="//g' -e 's/".*//g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку. Нужно для определения имени файла картинки
				LINK_PIC=$(curl -# -k -L -A "$UA" --compressed $(sed -n "$j p" pics_$i.txt) | sed -n '/id=\"image\"/p' | sed -e 's/.*img src="/http:/' -e 's/".*//' -e 's/amp;//')
				
				# Получаем полное имя файла из ссылки на файл
				PIC_NAME=$(echo "$LINK_PIC" | sed -e 's/\?token.*//' -e 's/.*\///')
				
				# Определяем, какое имя для картинки использовать. Зависит от переменной в начале скрипта
				Determ_name
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как mangakakalot.com или его зеркала.
	mangakakalot.com | manganato.com | readmanganato.com)
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/\(<span><a href="\)\|\(class="chapter-name text-nowrap\)/p' | sed -e 's/.*href="//g' -e 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/^<img src="/p' | sed '/logo.chap.png/d' | sed -e 's/^<img src="//' -e 's/><img src="/\n/g' | sed 's/".*//g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/vol_\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed 's/.*\.//'))
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как MyToon (бывший Heaventoon) и его многочисленные зеркала.
	# Здесь перечислены все возможные адреса для этого парсера. Обратные слэши в конце строк экранируют символы окончания строк, чтобы все эти строки воспринимались как одна.
	mytoon.net | ww5.heaventoon.com | heavenmanga.biz | heavenmanga.ca | heavenmanga.club | heavenmanga.co | heavenmanga.com | heavenmanga.fun | heavenmanga.life | heavenmanga.live | heavenmanga.online | heavenmanga.org | heavenmanga.pw | heavenmanga.space | heavenmanga.stream | heavenmanga.today | heavenmanga.top | heavenmanga.vip | heavenmanga.website | heavenmanga.win | heavenmanga.world | heavenmanga.xyz | holymanga.net | hvmanga.com | heavenmanga.ca | ww0.heavenmanga.vip | ww1.heavenmanga.vip | ww2.heavenmanga.vip | ww3.heavenmanga.vip | heaventoon.com | ww0.heaventoon.com | ww1.heaventoon.com | ww2.heaventoon.com | ww3.heaventoon.com | ww4.heaventoon.com | ww1.heavenmanga.org | ww2.heavenmanga.org | ww3.heavenmanga.org | ww4.heavenmanga.org | ww5.heavenmanga.org | ww6.heavenmanga.org | ww7.heavenmanga.org | ww8.heavenmanga.org |\
	w27.holymanga.net | w26.holymanga.net | w25.holymanga.net | w24.holymanga.net | w23.holymanga.net | w22.holymanga.net | w21.holymanga.net | w20.holymanga.net | w19.holymanga.net | w18.holymanga.net | w17.holymanga.net | w16.holymanga.net | w15.holymanga.net | w14.holymanga.net | w13.holymanga.net | w12.holymanga.net | w11.holymanga.net | w10.holymanga.net | ww9.holymanga.net | ww8.holymanga.net | ww7.holymanga.net | ww6.holymanga.net | ww5.holymanga.net | ww4.holymanga.net | ww3.holymanga.net | ww2.holymanga.net | ww1.holymanga.net | ww0.holymanga.net |\
	w10.bulumanga.net | ww9.bulumanga.net | ww8.bulumanga.net | ww7.bulumanga.net | ww6.bulumanga.net | ww5.bulumanga.net | ww4.bulumanga.net | ww3.bulumanga.net | ww2.bulumanga.net | ww1.bulumanga.net | bulumanga.net |\
	w10.koomanga.com | ww9.koomanga.com | ww8.koomanga.com | ww7.koomanga.com | ww6.koomanga.com | ww5.koomanga.com | ww4.koomanga.com | ww3.koomanga.com | ww2.koomanga.com | ww1.koomanga.com | www.koomanga.com)
		
		# Если адрес сайта определён как устаревший выполняем подмену на актуальный.
		case $SITE in
			
			# Здесь указаны актуальные адреса для этого парсера. Совпадение означает "всё ОК, продолжаем дальше".
			mytoon.net | w27.holymanga.net | ww9.bulumanga.net | w10.koomanga.com)
			;;
			
			# Здесь перечислены все старые адреса MyToon.
			ww5.heaventoon.com | heavenmanga.biz | heavenmanga.ca | heavenmanga.club | heavenmanga.co | heavenmanga.com | heavenmanga.fun | heavenmanga.life | heavenmanga.live | heavenmanga.online | heavenmanga.org | heavenmanga.pw | heavenmanga.space | heavenmanga.stream | heavenmanga.today | heavenmanga.top | heavenmanga.vip | heavenmanga.website | heavenmanga.win | heavenmanga.world | heavenmanga.xyz | holymanga.net | hvmanga.com | heavenmanga.ca | ww0.heavenmanga.vip | ww1.heavenmanga.vip | ww2.heavenmanga.vip | ww3.heavenmanga.vip | heaventoon.com | ww0.heaventoon.com | ww1.heaventoon.com | ww2.heaventoon.com | ww3.heaventoon.com | ww4.heaventoon.com | ww1.heavenmanga.org | ww2.heavenmanga.org | ww3.heavenmanga.org | ww4.heavenmanga.org | ww5.heavenmanga.org | ww6.heavenmanga.org | ww7.heavenmanga.org | ww8.heavenmanga.org)
				
				# Здесь указан актуальный адрес MyToon.
				SITE=mytoon.net
				Change_site_message
			;;
			
			# Здесь перечислены все старые адреса HolyManga.
			w26.holymanga.net | w25.holymanga.net | w24.holymanga.net | w23.holymanga.net | w22.holymanga.net | w21.holymanga.net | w20.holymanga.net | w19.holymanga.net | w18.holymanga.net | w17.holymanga.net | w16.holymanga.net | w15.holymanga.net | w14.holymanga.net | w13.holymanga.net | w12.holymanga.net | w11.holymanga.net | w10.holymanga.net | ww9.holymanga.net | ww8.holymanga.net | ww7.holymanga.net | ww6.holymanga.net | ww5.holymanga.net | ww4.holymanga.net | ww3.holymanga.net | ww2.holymanga.net | ww1.holymanga.net | ww0.holymanga.net)
				
				# Здесь указан актуальный адрес HolyManga.
				SITE=w27.holymanga.net
				Change_site_message
			;;
			
			# Здесь перечислены все старые адреса BuluManga.
			ww9.bulumanga.net | ww8.bulumanga.net | ww7.bulumanga.net | ww6.bulumanga.net | ww5.bulumanga.net | ww4.bulumanga.net | ww3.bulumanga.net | ww2.bulumanga.net | ww1.bulumanga.net | bulumanga.net)
				
				# Здесь указан актуальный адрес BuluManga.
				SITE=w10.bulumanga.net
				Change_site_message
			;;
			
			# Здесь перечислены все старые адреса KooManga.
			ww9.koomanga.com | ww8.koomanga.com | ww7.koomanga.com | ww6.koomanga.com | ww5.koomanga.com | ww4.koomanga.com | ww3.koomanga.com | ww2.koomanga.com | ww1.koomanga.com | www.koomanga.com)
				
				# Здесь указан актуальный адрес KooManga.
				SITE=w10.koomanga.com
				Change_site_message
			;;
			
			# Если забыли добавить устаревший адрес в кейс.
			*)
				echo -e "\e[1;31m  Вы забыли добавить сайт \"$SITE\" в список устаревших для данного парсера!\e[0m" ; echo
				sleep 5 ; exit
		    ;;
		esac
		
		# Проверяем адрес и переопределяем при необходимости.
		Adres_check_replace
		
		# Сохраняем файл с адресом. При необходимости заменяем на актуальный.
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] || [ $SITE != $(cat adres.txt | sed -e 's|.*://||' -e 's|/.*||') ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше. Скачиваем html страницы описания, находим ссылку на первую попавшуюся главу, скачиваем её html и из селектора глав формируем список. Ссылку на главу с селектором можно искать с помощью grep -m 1 , но тогда возникают затупы у curl-а. С sed-ом в данном случае проще.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" $(curl -# -k -L -A "$UA" "$ADRES" | sed -n '/h2 class="chap"/p' | sed -n "1p" | sed -e 's/.*href="//' -e 's/".*/\//') | sed -n '/<option  value="/p' | sed 's/">/\/\n/g' | sed -e 's/.*="//g' -e '/https:/!d' > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Определяем номер тома текущей главы.
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e 's/-ch\(ap\)\?-.*//' -e 's/.*[^0-9]//')
			
			# Формируем файл с адресами картинок. На этом сайте ТАКОЕ разнообразие синтаксиса!!! Проще найти все похожие ссылки, удалить из них ссылки с логотипами. Кавычки на сайте используются то двойные, то одинарные.
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/<img.*src=/p' | sed -e '/\/logo.png/d' -e '/\/load.gif/d' -e '/\/fb.png/d' -e '/play.google.com/d' -e '/idzone=/d' | sed "s/=[\"\']/\n/g" | sed -e "s/[\"\'].*//g" -e '/https\?:/!d' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed 's/.*\.//'))
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как unicomics.ru
	unicomics.ru | www.unicomics.ru)
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше. Скачиваем html страницы описания, находим ссылку на первую попавшуюся главу, скачиваем её html и из селектора глав формируем список. Ссылку на главу с селектором можно искать с помощью grep -m 1 , но тогда возникают затупы у curl-а. С sed-ом в данном случае проще.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$(curl -# -k -L -A "$UA" "$ADRES" | sed -n '/div class="button bold descr"/p' | sed -n "1p" | sed -e 's/.*a href="//' -e 's/".*//')" | sed -n '/scroll-pane-arrows/p' | sed 's/.*arrows"><a href="//' | sed 's/href="/\n/g' | sed 's/".*//g' | sed "s/^/https:\/\/$SITE\//g" > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# На этом сайте разбивки по главам нет. В зависимости от выбора ниже, комиксы могут вместо папок глав скачиваться в папки томов
			
			# Получаем в переменную адрес текущего тома, не забывая экранировать слеши
			CH_ADRES=$(sed -n "$i p" ch_adreses.txt | sed 's/\//\\\//g')
			
			# Формируем файл с непрямыми ссылками на картинки текущего тома, для чего из paginator-а html-а определим количество старниц в томе, выведем список чисел (страниц), начиная с 1, и подставим в начало строк адрес тома
			seq 1 $(curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/script type.*paginator1/p' | sed -e 's/.*paginator1", //' -e 's/,.*//') | sed "s/^/$CH_ADRES\//g" > pics_$i.txt
			
			# Определяем  какую разбивку картинок использовать, по томам или главам и отправляем в переменную путь скачивающегося тома. Переменная требуется для дальнейшей проверки полноты закачки.
			Separation_by
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки.
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла.
				LINK_PIC="$(curl -# -k -L -A "$UA" $(sed -n "$j p" pics_$i.txt) | sed -n '/<img id/p' | sed -e 's/.*src="//' -e 's/".*//')"
				
				# Получаем полное имя файла с помощью ссылки на файл
				PIC_NAME=$(echo $LINK_PIC | sed 's/.*\///')
				
				# Определяем, какое имя для картинки использовать. Зависит от переменной в начале скрипта
				Determ_name
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как manga24.ru
	manga24.ru)
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/a href=".*chapter-link/p' | sed -e "s|.*href=\"|https://$SITE|g" -e 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Выделяем из html-а полный путь картинок и передаём в переменную, попутно экранируем слеши в пути
			PICS_LOCATION=$(curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n "/dir:/p" | sed -e 's|.*Content|https://manga24.ru/Content|' -e 's/".*//' -e 's|/|\\/|g')
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n "/images:/p" | sed -e 's/.*\[\["//g' -e 's/\],\["/\n/g' | sed 's/".*//g' | sed "s/^/"$PICS_LOCATION"/g" > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/vol_\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Получаем полное имя файла из ссылки на файл
				PIC_NAME=$(echo $LINK_PIC | sed 's/.*\///')
				
				# Определяем, какое имя для картинки использовать. Зависит от переменной в начале скрипта
				Determ_name
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как All Hentai
	# Здесь перечислены все возможные адреса для этого парсера.
	23.allhen.online | 24.allhen.online | wwv.allhen.live | wwv.allhen.me | allhentai.ru)
	
		# Получаем имя манги
		COMIC_NAME=$(echo $ADRES | sed -e "s/.*$SITE\///" -e "s/\/.*//")
		
		# Для старых адресов сайта выполняем замену на актуальный.
		# Если адрес сайта не равен актуальному...
		if [ $SITE != 23.allhen.online ] ; then
			
			# ... заменяем его на актуальный.
			SITE=23.allhen.online
			Change_site_message
		fi
		
		# Проверяем адрес и переопределяем при необходимости.
		Adres_check_replace
		
		# Сохраняем файл с адресом. При необходимости заменяем на актуальный.
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] || [ $SITE != $(cat adres.txt | sed -e 's|.*://||' -e 's|/.*||') ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "http://$SITE/$COMIC_NAME" | sed -n "/.*<a href.*\/vol.*/p" | sed -e "/>.*</d" -e '/;page=/d' | sed -e "s/.*<a href=\"/http:\/\/$SITE/g" -e 's/".*/\?mtr=1/g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав.
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
			
			# Определяем номер тома текущей главы
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e 's/.*vol//' -e 's/\/.*//')
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed  -n '/rm_h.init/p' | sed -e "s/^.*\[\['/http:/" -e "s/\]\].*//" -e 's/\],\[./\nhttp:/g' | awk 'BEGIN { FS=".,." } { print $1 $3 }' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки. Можно обойтись без этой строки, пригодится для обобщения методов
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Получаем полное имя файла из ссылки на файл
				PIC_NAME=$(echo "$LINK_PIC" | sed -e 's/\?t=.*//' -e 's/.*\///')
				
				# Определяем, какое имя для картинки использовать. Зависит от переменной в начале скрипта
				Determ_name
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как desu.me
	desu.me)
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/<h4>/p' | sed -e 's/.*href="/https:\/\/desu.me/g' -e 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Определяем номер тома текущей главы
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e 's/.*vol//' -e 's/\/.*//')
			
			# Скачиваем и отдаём в переменную весь html главы.
			TEMP_HTML=$(curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt))
			
			# Выделяем из html-а полный путь картинок и передаём в переменную
			PICS_LOCATION=$(echo "$TEMP_HTML" | sed -n "/dir:/p" | sed -e 's/.*dir: "/https:/' -e 's/".*//')
			
			# Формируем файл с адресами картинок
			echo "$TEMP_HTML" | sed -n '/images:/p' | sed -e 's/.*\[\["//g' -e 's/\],\["/\n/g' | sed 's/".*//g' | sed "s/^/"$PICS_LOCATION"/g" > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Получаем полное имя файла из ссылки на файл
				PIC_NAME=$(echo $LINK_PIC | sed 's/.*\///')
				
				# Определяем, какое имя для картинки использовать. Зависит от переменной в начале скрипта
				Determ_name
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как reader.onibaku.ru
	reader.onibaku.ru)
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/title.*title=/p' | sed -e 's/.*href=\"//g' -e 's/\".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Определяем номер тома текущей главы
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e 's/.*\/ru\///' -e 's/\/.*//')
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/var pages/p' | sed 's/http/\nhttp/g' | sed -n '/thumb_url/p' | sed -e 's/\".*//g' -e 's/\\\//\//g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Получаем полное имя файла из ссылки на файл
				PIC_NAME=$(echo $LINK_PIC | sed 's/.*\///')
				
				# Определяем, какое имя для картинки использовать. Зависит от переменной в начале скрипта
				Determ_name
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как mangaclub.ru
	mangaclub.ru)
		
		# Получаем имя манги
		COMIC_NAME=$(echo $ADRES | sed -e "s|.*$SITE/||" -e 's/.htm.*//')
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n "/$SITE\/manga\/view\/$COMIC_NAME/p" | sed -e 's/.*href="//g' -e 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Определяем номер тома текущей главы
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e 's/.*\/v//g' -e 's/-c.*//g')
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/manga-lines mangaPage/p' | sed -e "s|.*data-i=\"|https://img.mangaclub.ru/|g" -e 's/".*//g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Получаем полное имя файла из ссылки на файл
				PIC_NAME=$(echo $LINK_PIC | sed 's/.*\///')
				
				# Определяем, какое имя для картинки использовать. Зависит от переменной в начале скрипта
				Determ_name
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как mangalib.me
	mangalib.me | www.mangalib.me | mangalib.org)
		
		# Получаем имя манги
		COMIC_NAME=$(echo $ADRES | sed -e "s|.*$SITE/||" -e "s|/.*||" -e 's/\?.*//')
		
		# Получаем ID команды переводчиков. Если BID пуст присваиваем ему значение null (один переводчик).
		BID=$(echo $ADRES | sed -e 's/&*page.*//' -e "s/.*?\(bid=\)*//") ; BID=${BID:-null}
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			
			# Для начала определим какая ссылка используется в качестве начальной. Если используется ссылка со страницы описания (любая секция) - формируем список ссылок от всех переводчиков, иначе - список содержит только главы переводчика стартовой главы.
			if [ $(echo $ADRES | sed -n '/section=/p') ] ; then
				
				# Ссылка со страницы описания - формируем полный список глав.
				curl -# -k -L -A "$UA" "https://$SITE/$COMIC_NAME" | sed -n '/window.__DATA__/p' | sed -e 's/}\].*//' -e 's/.*\[{//' | sed "s/},{/\n/g" | sed -n '/^"chapter_id"/p' | sed -e 's/.*"chapter_number":"/c/g' -e 's/","chapter_volume":/-v/g' -e 's/,.*"branch_id":/-bid=/g' -e 's/,.*//g' | tac | sed 's/null//g' | awk 'BEGIN { FS="-" } { print $2 "/" $1 "?" $3 }' | sed "s|^|https://$SITE/$COMIC_NAME/|g" | Sort_bid > ch_adreses.txt
			else
				# Ссылка со страницы главы - вормируем список с главами только одного переводчика.
				curl -# -k -L -A "$UA" "https://$SITE/$COMIC_NAME" | sed -n '/window.__DATA__/p' | sed -e 's/}\].*//' -e 's/.*\[{//' | sed "s/},{/\n/g" | sed -n '/^"chapter_id"/p' | sed -e 's/.*"chapter_number":"/c/g' -e 's/","chapter_volume":/-v/g' -e 's/,.*"branch_id":/-bid=/g' -e 's/,.*//g' | tac | sed -n "/$BID/p" | sed 's/null//g' | awk 'BEGIN { FS="-" } { print $2 "/" $1 "?" $3 }' | sed "s|^|https://$SITE/$COMIC_NAME/|g" > ch_adreses.txt
			fi
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Определяем номер тома текущей главы
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e 's/.*\/v//g' -e 's/\/.*//g')
			
			# Скачиваем и отдаём в переменную весь html главы.
			TEMP_HTML=$(curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt))
			
			# Определяем адрес сервера картинок исходя из переменной в начале скрипта.
			SERVER_ADRES=$(echo "$TEMP_HTML" | sed -n '/"servers":/p' | sed -e "s/.*$LIB_SERVER\":\"//" -e 's/".*//')
			
			# Выделяем из html-а полный путь картинок, попутно меняя адрес сервера картинок, и передаём в переменную
			PICS_LOCATION=$(echo "$TEMP_HTML" | sed -n '/property="og:image"/p' | sed -e 's/.*content="//' -e 's/".*//' -e "s|.*mangalib.me|$SERVER_ADRES/|" -e 's|/[^/]*$|/|' -e 's|/|\\/|g')
			
			# Формируем файл с адресами картинок.
			echo "$TEMP_HTML" | sed -n '/window.__pg/p' | sed 's/"},{"/\n/g' | sed -e "s/.*:\"/$PICS_LOCATION/g" -e 's/".*//g' -e 's/ /%20/g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed 's/.*\.//'))
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как mangahub.ru
	mangahub.ru)
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/<a class=.*href=".*read/p' | sed -e "s|.*href=\"|https://mangahub.ru|g" -e 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Определяем номер тома текущей главы
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e 's/.*vol//' -e 's/\/.*//')
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/reader data-store=/p' | sed 's|\\||g' | sed 's|//|\n//|g' | sed -n '/media/p' | sed -e 's/^/https:/g' -e 's/&.*//g' -e '/manga_cover/d' -e '/thumbnail/d' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed 's/.*\.//'))
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как www.webtoons.com или его мобильная версия m.webtoons.com
	www.webtoons.com | m.webtoons.com)
		
		# Получаем имя комикса
		COMIC_NAME=$(echo $ADRES | sed -e 's/\/list.*//' -e "s/.*\///")
		
		# Если введён мобильный адрес, подменяем его на полный. Закачка производится только с полного адреса.
		ADRES=$(echo "$ADRES" | sed 's/m.webtoons.com/www.webtoons.com/')
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Переопределяем переменную $SITE, чтобы избежать дублирования файла с адресом главы в папке с картинками, иначе сначала формируется файл со ссылкой на полную версию сайта и таким же именем, а при повторной закачке в эту же папку (сбой, недокачалось) формируется ещё и файл со ссылкой на мобильную версию сайта. 
		SITE=$(echo $ADRES | sed "s/.*:\/\///" | sed "s/\/.*//")
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		# Выражение sed '/data-episode-no/{n;p;}' ищет строку, идущую после строки с поисковым выражением "data-episode-no". Выражение с awk удаляет дубли строк.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" $(curl -# -k -L -A "$UA" $ADRES | sed -n "/	<a href=\"https:\/\/www.webtoons.com.*$COMIC_NAME.*class=\"NPI/p" | sed -n "1p" | sed -e 's/.*href="//' -e 's/".*//') | sed -n '/data-episode-no/{n;p;}' | sed -n '/http/p' | sed -e 's/.*href="//g' -e 's/".*//g' | awk '!x[$0]++' > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# На этом сайте разбивки по томам нет
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/class="_images"/p' | sed -e 's/.*data-url="//g' -e 's/".*//g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/vol_\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed -e 's/.*\.//' -e 's/\?.*//'))
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как read.yagami.me
	read.yagami.me)
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/class="element"/p' | sed -e 's/.*href="//g' -e 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# Определяем номер тома текущей главы
			COMIC_NAME=$(sed -n "$i p" ch_adreses.txt | sed -e 's|.*/read/||' -e 's|/.*||')
			VOL_NUM=$(sed -n "$i p" ch_adreses.txt | sed -e "s|.*$COMIC_NAME/||" -e 's|/.*||')
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/var pages/p' | sed -e 's/":"/\n/g' -e 's|\\||g' | sed -n '/http/p' | sed 's/".*//g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/"vol_$VOL_NUM"\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Получаем полное имя файла из ссылки на файл
				PIC_NAME=$(echo $LINK_PIC | sed 's/.*\///')
				
				# Определяем, какое имя для картинки использовать. Зависит от переменной в начале скрипта
				Determ_name
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как com-x.life
	com-x.life)
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			
			# Скачиваем html страницы описания, находим ссылку на последнюю главу на странице (последнюю ссылку искать проще используя жадность регэкспов), скачиваем её html и полностью отдаем в переменную.
			TEMP_HTML=$(curl -# -k -L -A "$UA" "$(curl -# -k -L -A "$UA" "$ADRES" | sed -n '/\/readcomix\//p' | sed -e "s/.*\/readcomix/https:\/\/$SITE\/readcomix/" -e 's/".*//')")
			
			# Получаем ID комикса.
			comix_id=$(echo "$TEMP_HTML" | sed -n '/"news_id"/p' | sed -e 's/.*"news_id"://' -e 's/,.*//')
			
			# Формируем файл с адресами глав.
			echo "$TEMP_HTML" | sed -n '/window.__DATA__/p' | sed -e 's/.*\[{//' -e 's/}\].*//' | sed "s/},{/\n/g" | sed -e "s|.*\"id\":|https://$SITE/readcomix/"$comix_id"/|g" -e 's/,".*/.html/g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# На этом сайте разбивка по томам есть, но в ссылках на главы этой информации нет
			
			# Формируем файл с адресами картинок.
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/"images"/p' | sed -e 's/.*"images":\["//' -e 's/"\].*/\n/' | sed 's/","/\n/g' | sed -e "s|^|https://img.com-x.life/comix/|g" -e 's/\\\//\//g' > pics_$i.txt
			
			# Определяем  какую разбивку картинок использовать, по томам или главам и отправляем в переменную путь скачивающегося тома. Переменная требуется для дальнейшей проверки полноты закачки.
			Separation_by
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed 's/.*\.//'))
				
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как manhwa18.com или manhwa18.net
	manhwa18.com | manhwa18.net)
	
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/class="chapter"/p' | sed -e "s|.*href='|https://$SITE/|g" -e "s/'.*//g" | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# На этом сайте разбивки по томам нет
			
			# Формируем файл с адресами картинок. Выражение sed 's/\r$//g' меняет Виндовые переводы строк (CRLF) на Линуксовые (LF).
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/data-original=/p' | sed "s/data-original='/\n/g" | sed -n '/^http\|^app/p' | sed -e "s|^app|https://$SITE/app|g" -e "s/'.*//g" -e "s|/imgur.com/|/i.imgur.com/|g" -e 's/ /%20/g' | sed 's/\r$//g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/vol_\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки.
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed 's/.*\.//'))
				
				# В папке с комиксом создаём файл "no_referer", если его там нет. Без этого с некоторых серверов (i.ibb.co) скачиваются не картинки, а их превьюшки.
				if [ ! -f no_referer -o -f no_referer.txt ] ; then
					touch "no_referer.txt"
				fi
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как mangarussia.com
	mangarussia.com | www.mangarussia.com)
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/td class="col1"/p' | sed -e 's/.*href="//g' -e 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# На этом сайте разбивка по томам есть, но пока с этим сложно - разный синтаксис при указании номера тома
			
			# Формируем файл с непрямыми ссылками на картинки текущей главы. Выражение с awk удаляет дубли строк.
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n "/<option value.*>[[:digit:]]*<\/option>/p" | awk '!x[$0]++' | sed -e 's/.*value="//g' -e 's/".*//g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/vol_\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла.
				LINK_PIC="$(curl -# -k -L -A "$UA" $(sed -n "$j p" pics_$i.txt) | sed -n "/img id='comicpic'/p" | sed -e 's/.*src="//' -e 's/".*//')"
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed 's/.*\.//'))
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как mangapark.net
	mangapark.net)
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" -b set=h=1 "$ADRES" | sed -n '/a class="ml-1/p' | sed -e "s|.*href=\"|https://$SITE|g" -e 's/".*//g' -e 's|/1||g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# На этом сайте разбивка по томам есть, но присутствует не во всех ссылках на главы.
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" -b set=h=1 $(sed -n "$i p" ch_adreses.txt) | sed -n '/var _load_pages/p' | sed 's/},{/\n/g' | sed -e 's/.*http/http/g' -e 's/".*//g' -e 's|\\||g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/vol_\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed 's/.*\.//'))
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как onlinemanga.xyz
	# Здесь перечислены все возможные адреса для этого парсера.
	r2.onlinemanga.xyz | onlinemanga.xyz)
		
		# Для старых адресов сайта выполняем замену на актуальный.
		# Если адрес сайта не равен актуальному...
		if [ $SITE != r2.onlinemanga.xyz ] ; then
			
			# ... заменяем его на актуальный.
			SITE=r2.onlinemanga.xyz
			Change_site_message
		fi
		
		# Проверяем адрес и переопределяем при необходимости.
		Adres_check_replace
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] || [ $SITE != $(cat adres.txt | sed -e 's|.*://||' -e 's|/.*||') ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/<td><a href="/p' | sed -e "s|.*href=\"|https://$SITE|g" -e 's/".*//g' > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# На этом сайте разбивки по томам нет
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/data-shard/p' | sed -e 's/.*href="//g' -e 's/".*//g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/vol_\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed 's/.*\.//'))
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как ReadComicOnline.
	# Здесь перечислены все возможные адреса для этого парсера.
	readcomiconline.li | readcomiconline.to)
		
		# Для старых адресов сайта выполняем замену на актуальный.
		# Если адрес сайта не равен актуальному...
		if [ $SITE != readcomiconline.li ] ; then
			
			# ... заменяем его на актуальный.
			SITE=readcomiconline.li
			Change_site_message
		fi
		
		# Проверяем адрес и переопределяем при необходимости.
		Adres_check_replace
		
		# Сохраняем файл с адресом. При необходимости заменяем на актуальный.
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] || [ $SITE != $(cat adres.txt | sed -e 's|.*://||' -e 's|/.*||') ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/<li>.*href="\/Comic\//p' | sed -e "s|.*href=\"|https://$SITE|g" -e 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# На этом сайте разбивки по главам нет. В зависимости от выбора ниже, комиксы могут вместо папок глав скачиваться в папки томов
			
			# Формируем файл с адресами картинок. Последнее выражение для отмены масштабирования, переключение с низкого качества на высокое.
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/lstImages.push/p' | sed -e 's/.*http/http/g' -e 's/".*//g' -e 's/=s.*/=s0/g' > pics_$i.txt
			
			# Определяем  какую разбивку картинок использовать, по томам или главам и отправляем в переменную путь скачивающегося тома. Переменная требуется для дальнейшей проверки полноты закачки.
			Separation_by
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки. Нужно для сохранения картинок с правильными именами
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение поставил от балды, всё равно его перепроверять, а вдруг совпадёт.
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".jpg)
				
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как manhwa18.cc
	manhwa18.cc)
		
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/class="chapter-name/p' | sed -e "s|.*href=\"|https://$SITE|g" -e 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# На этом сайте разбивки по томам нет
			
			# Формируем файл с адресами картинок
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/img class=/p' | sed 's/. alt=/\n/g' | sed "s/.*'//g" | sed -n '/http/p' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/vol_\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed 's/.*\.//'))
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как ja.mangatoro.com
	ja.mangatoro.com)
	
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/class="row heading"/p' | sed 's/href="/\n/g' | sed -n '/http/p' | sed 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# На этом сайте разбивки по томам нет
			
			# Формируем файл с адресами картинок.
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/data-original/p' | sed "s/data-original='/\nhttps:/g" | sed -n '/http/p' | sed "s/'.*//g" > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/vol_\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки.
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed 's/.*\.//'))
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт определён как mangas-raw.com
	mangas-raw.com)
	
		# Сохраняем файл с адресом
		if [ ! -f adres.txt ] || [ ! -s adres.txt ] ; then
			echo "$ADRES" > adres.txt
		fi
		
		# Если файл с адресами глав отсутствует или пуст, формируем его. Если он есть и заполнен - продолжаем дальше.
		if [ ! -f ch_adreses.txt ] || [ ! -s ch_adreses.txt ] ; then
			curl -# -k -L -A "$UA" "$ADRES" | sed -n '/class="eph-num"/{n;p;}' | sed -e 's/.*href="//g' -e 's/".*//g' | tac > ch_adreses.txt
		fi
		
		# Проверка файла ch_adreses.txt на непустоту.
		Check_ch_adreses
		
		# Выбор количества закачиваемых глав. Завершить цикл с помощью done!
		Download_choice
		
		# Проверяем, что переменная i меньше номера последней главы
		while [ $i -le $E_CHAP ] ; do
		
			# На этом сайте разбивки по томам нет
			
			# Формируем файл с адресами картинок.
			curl -# -k -L -A "$UA" $(sed -n "$i p" ch_adreses.txt) | sed -n '/img class=/p' | sed -e 's/.*data-src="//g' -e 's/".*//g' > pics_$i.txt
			
			# Отправляем в переменную путь скачивающейся главы. Переменная требуется для дальнейшей проверки полноты закачки
			PICS_PATH=Pics\/vol_\/"$(printf "%03d" $i)"
			
			# Создаём папку для скачиваемых картинок комикса
			mkdir -p "$PICS_PATH"
			
			# Создаём в папке с главой текстовый файл с адресом главы
			Save_chapter_link
			
			# Скачиваем главу, циклом перебирая ссылки.
			# Присваиваем переменной j номер первой строки
			j=1
			while read line
			do
				
				# Получаем прямую ссылку на картинку из файла. Нужно для определения имени файла картинки.
				LINK_PIC=$(sed -n "$j p" pics_$i.txt)
				
				# Определяем полное имя файла, расширение определяем с помощью ссылки на файл
				PIC_NAME=$(echo "Page_$(printf "%03d" $j)".$(echo $LINK_PIC | sed 's/.*\.//'))
				
				# Закачка картинок и проверка. Часть цикла.
				Downloading_pics
				
				# Увеличиваем j на единицу
				j=$(($j+1))
				
			done < pics_$i.txt
			
			# Проверка закачки
			Down_check
			
			# Увеличиваем i на единицу.
			i=$(($i+1))
		
		done
		
		# Файл завершения закачки.
		Echo_finish
		
		# Упаковка закачанного в CBZ.
		Pack_to_CBZ
	;;

	# Если сайт не опознан
	*)
		echo -e "\e[1;31m  Во введённой ссылке недопустимый адрес\e[0m"
		echo -e "\e[1;31m  или в файле adres.txt неверная ссылка.\e[0m"
		echo -e "\e[1;31mЕсли верно второе - удалите файл adres.txt\e[0m"
		echo -e "\e[1;31m     и запустите качалку ещё раз.\e[0m"
		echo
		sleep 5
	;;

# =====> Парсеры. Конец <===============================================

esac
